{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation,TimeDistributed\n",
    "from keras.layers import Bidirectional, LSTM\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate,BatchNormalization,MaxPooling1D, Convolution1D\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D, RepeatVector, Permute, merge\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 5000\n",
    "MAX_NUM_WORDS = 25000\n",
    "EMBEDDING_DIM = 300\n",
    "TEST_SPLIT = 0.3\n",
    "EMBEDDING_FILE=f'glove.6B.{EMBEDDING_DIM}d.txt'\n",
    "TEXT_DATA = 'data/fake_or_real_news.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate 95% confidence interval on error\n",
    "\n",
    "# NOTE: based on conversation on stackexchange: \n",
    "# https://stats.stackexchange.com/questions/247551/how-to-determine-the-confidence-of-a-neural-network-prediction\n",
    "# towards bottom of the page.\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "def error_conf(error, n):\n",
    "    term = 1.96*sqrt((error*(1-error))/n)\n",
    "    lb = error - term\n",
    "    ub = error + term\n",
    "    \n",
    "    return lb, ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that allows us to evaluate our models\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model(predict_fun, X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    evaluate the model, both training and testing errors are reported\n",
    "    '''\n",
    "    # training error\n",
    "    y_predict_train = predict_fun(X_train)\n",
    "    train_acc = accuracy_score(y_train,y_predict_train)\n",
    "    \n",
    "    # testing error\n",
    "    y_predict_test = predict_fun(X_test)\n",
    "    test_acc = accuracy_score(y_test,y_predict_test)\n",
    "    \n",
    "    return train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in our data and preprocess it\n",
    "\n",
    "df = pd.read_csv(TEXT_DATA)\n",
    "df.drop(labels=['id','title'], axis='columns', inplace=True)\n",
    "# only select stories with lengths gt 0 -- there are some texts with len = 0\n",
    "mask = list(df['text'].apply(lambda x: len(x) > 0))\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6335 texts.\n"
     ]
    }
   ],
   "source": [
    "# prepare text samples and their labels\n",
    "\n",
    "texts = df['text']\n",
    "labels = df['label']\n",
    "\n",
    "print('Found %s texts.' %texts.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 99682 unique tokens.\n",
      "Shape of data tensor: (6335, 5000)\n",
      "Shape of label tensor: (6335,)\n"
     ]
    }
   ],
   "source": [
    "# vectorize the text samples into a 2D integer tensor \n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
    "data = pad_sequences(sequences, \n",
    "                     maxlen=MAX_SEQUENCE_LENGTH, \n",
    "                     padding='pre', \n",
    "                     truncating='pre')\n",
    "\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the glove word vectors (space delimited strings) into a dictionary from word->vector.\n",
    "\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE, encoding=\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Use these vectors to create our embedding matrix, with random initialization for words that aren't in GloVe. We'll use the same mean and stdev of embeddings the GloVe has when generating the random init\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean,emb_std\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(MAX_NUM_WORDS, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NUM_WORDS: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training set and a validation set   \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(data, \n",
    "                                                  labels.apply(lambda x: 0 if x == 'FAKE' else 1), \n",
    "                                                  test_size=TEST_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    '''\n",
    "    metric from here \n",
    "    https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
    "    '''\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    # So we only measure F1 on the target y value:\n",
    "    y_true = y_true[:, 0]\n",
    "    y_pred = y_pred[:, 0]\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # build a 1D convnet with global maxpooling                                                                      \n",
    "\n",
    "\n",
    "# model = Sequential(\n",
    "#     [\n",
    "#         # part 1: word and sequence processing\n",
    "#         layers.Embedding(MAX_NUM_WORDS,\n",
    "#                          EMBEDDING_DIM,\n",
    "#                          input_length=MAX_SEQUENCE_LENGTH,\n",
    "#                          weights=[embedding_matrix]),\n",
    "#         layers.Conv1D(128, 5, activation='relu'),\n",
    "#         layers.GlobalMaxPooling1D(),\n",
    "        \n",
    "#         # part 2: classification\n",
    "#         layers.Dense(128, activation='relu'),\n",
    "#         layers.Dense(1, activation='sigmoid')\n",
    "#     ])\n",
    "\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 5000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5000, 300)    7500000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 4998, 10)     9010        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 4993, 10)     24010       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 2499, 10)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 2496, 10)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 24990)        0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 24960)        0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 49950)        0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 49950)        0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 50)           2497550     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            51          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 10,030,621\n",
      "Trainable params: 10,030,621\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dropout_prob = [0.2,0.2]\n",
    "hidden_dims = 50\n",
    "filter_sizes  = (3,8)\n",
    "num_filters = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "input_shape = (MAX_SEQUENCE_LENGTH,)\n",
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "\n",
    "\n",
    "z = Embedding(MAX_NUM_WORDS,\n",
    "              EMBEDDING_DIM,\n",
    "              weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH)(model_input)\n",
    "\n",
    "conv_blocks = []\n",
    "for sz in filter_sizes:\n",
    "    conv = Convolution1D(filters=num_filters,\n",
    "                         kernel_size=sz,\n",
    "                         padding=\"valid\",\n",
    "                         activation=\"relu\",\n",
    "                         strides=1)(z)\n",
    "    conv = MaxPooling1D(pool_size=2)(conv)\n",
    "    conv = Flatten()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "z = Dropout(dropout_prob[1])(z)\n",
    "z = Dense(hidden_dims, activation=\"relu\")(z)\n",
    "model_output = Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",f1])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file -p already exists.\n",
      "Error occurred while processing: -p.\n",
      "A subdirectory or file ./save/model/gloveCNN/ already exists.\n",
      "Error occurred while processing: ./save/model/gloveCNN/.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# training\n",
    "TRAINING_BATCH_SIZE      = 64\n",
    "# TRAINING_SHUFFLE_BUFFER  = 5000\n",
    "# TRAINING_BN_MOMENTUM     = 0.99\n",
    "# TRAINING_BN_EPSILON      = 0.001\n",
    "TRAINING_LR_MAX          = 0.001\n",
    "# TRAINING_LR_SCALE        = 0.1\n",
    "# TRAINING_LR_EPOCHS       = 2\n",
    "TRAINING_LR_INIT_SCALE   = 0.01\n",
    "TRAINING_LR_INIT_EPOCHS  = 3\n",
    "TRAINING_LR_FINAL_SCALE  = 0.01\n",
    "TRAINING_LR_FINAL_EPOCHS = 7\n",
    "\n",
    "# training (derived)\n",
    "TRAINING_NUM_EPOCHS = TRAINING_LR_INIT_EPOCHS + TRAINING_LR_FINAL_EPOCHS\n",
    "TRAINING_LR_INIT    = TRAINING_LR_MAX*TRAINING_LR_INIT_SCALE\n",
    "TRAINING_LR_FINAL   = TRAINING_LR_MAX*TRAINING_LR_FINAL_SCALE\n",
    "\n",
    "# saving\n",
    "SAVE_MODEL_PATH = './save/model/gloveCNN/'\n",
    "!mkdir -p \"$SAVE_MODEL_PATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "\n",
    "    # staircase\n",
    "    # lr = TRAINING_LR_MAX*math.pow(TRAINING_LR_SCALE, math.floor(epoch/TRAINING_LR_EPOCHS))\n",
    "\n",
    "    # linear warmup followed by cosine decay\n",
    "    if epoch < TRAINING_LR_INIT_EPOCHS:\n",
    "        lr = (TRAINING_LR_MAX - TRAINING_LR_INIT)*(float(epoch)/TRAINING_LR_INIT_EPOCHS) + TRAINING_LR_INIT\n",
    "    else:\n",
    "        lr = ((TRAINING_LR_MAX - TRAINING_LR_FINAL)*\n",
    "              max(0.0, math.cos(((float(epoch) - TRAINING_LR_INIT_EPOCHS)/\n",
    "                                 (TRAINING_LR_FINAL_EPOCHS - 1.0))*(math.pi/2.0))) + \n",
    "              TRAINING_LR_FINAL)\n",
    "\n",
    "    # debug - learning rate display\n",
    "    # print(epoch)\n",
    "    # print(lr)\n",
    "\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4434 samples, validate on 1901 samples\n",
      "Epoch 1/10\n",
      "4434/4434 [==============================] - 274s 62ms/step - loss: 0.0711 - accuracy: 0.9831 - f1: 0.9821 - val_loss: 0.0943 - val_accuracy: 0.9847 - val_f1: 0.9840\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09426, saving model to ./save/model/gloveCNN/model_1.h5\n",
      "Epoch 2/10\n",
      "4434/4434 [==============================] - 303s 68ms/step - loss: 0.0609 - accuracy: 0.9869 - f1: 0.9869 - val_loss: 0.0427 - val_accuracy: 0.9911 - val_f1: 0.9902\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09426 to 0.04270, saving model to ./save/model/gloveCNN/model_2.h5\n",
      "Epoch 3/10\n",
      "4434/4434 [==============================] - 329s 74ms/step - loss: 0.0183 - accuracy: 0.9966 - f1: 0.9968 - val_loss: 0.0511 - val_accuracy: 0.9911 - val_f1: 0.9903\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04270\n",
      "Epoch 4/10\n",
      "4434/4434 [==============================] - 306s 69ms/step - loss: 0.0099 - accuracy: 0.9991 - f1: 0.9991 - val_loss: 0.0807 - val_accuracy: 0.9868 - val_f1: 0.9859\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04270\n",
      "Epoch 5/10\n",
      "4434/4434 [==============================] - 331s 75ms/step - loss: 0.0056 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.0664 - val_accuracy: 0.9879 - val_f1: 0.9871\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04270\n",
      "Epoch 6/10\n",
      "4434/4434 [==============================] - 306s 69ms/step - loss: 0.0041 - accuracy: 1.0000 - f1: 1.0000 - val_loss: 0.0628 - val_accuracy: 0.9863 - val_f1: 0.9860\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04270\n",
      "Epoch 7/10\n",
      "4434/4434 [==============================] - 307s 69ms/step - loss: 0.0035 - accuracy: 1.0000 - f1: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9853 - val_f1: 0.9848\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04270\n",
      "Epoch 8/10\n",
      "4434/4434 [==============================] - 307s 69ms/step - loss: 0.0031 - accuracy: 1.0000 - f1: 1.0000 - val_loss: 0.0681 - val_accuracy: 0.9863 - val_f1: 0.9855\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04270\n",
      "Epoch 9/10\n",
      "4434/4434 [==============================] - 306s 69ms/step - loss: 0.0029 - accuracy: 1.0000 - f1: 1.0000 - val_loss: 0.0668 - val_accuracy: 0.9858 - val_f1: 0.9854\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04270\n",
      "Epoch 10/10\n",
      "4434/4434 [==============================] - 307s 69ms/step - loss: 0.0029 - accuracy: 1.0000 - f1: 1.0000 - val_loss: 0.0669 - val_accuracy: 0.9863 - val_f1: 0.9859\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04270\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "callbacks = [keras.callbacks.LearningRateScheduler(lr_schedule),\n",
    "             keras.callbacks.ModelCheckpoint(filepath=SAVE_MODEL_PATH+'model_{epoch}.h5', \n",
    "                                             save_best_only=True, monitor='val_loss', verbose=1)]\n",
    "\n",
    "initial_epoch_num = 0\n",
    "# example of restarting training after a crash from the last saved checkpoint\n",
    "# model.load_weights(SAVE_MODEL_PATH+'model_5.h5') # replace X with the last saved checkpoint number\n",
    "# initial_epoch_num = 5                            # replace X with the last saved checkpoint number\n",
    "\n",
    "\n",
    "history           = model.fit(x_train, \n",
    "                              y_train,shuffle=True,batch_size=TRAINING_BATCH_SIZE,\n",
    "                              epochs=TRAINING_NUM_EPOCHS, \n",
    "                              verbose=1, \n",
    "                              callbacks=callbacks, \n",
    "                              validation_data=(x_val, y_val), \n",
    "                              initial_epoch=initial_epoch_num)\n",
    "\n",
    "# previous version with 97% testing accuracy\n",
    "# history = model.fit(x_train, \n",
    "#                     y_train,\n",
    "#                     batch_size=128,\n",
    "#                     epochs=10,\n",
    "#                     validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl4lOX18PHvISSEJWwJmwYIAiL7YkAEFQTcraioQGtbV6p1a62tW3/a2lq1r20V16JiwVrQ4oYWRA2gKKgEZE8QRJawJGELa8h23j/uJzDEhEySeTKT5Hyua67MPMs9ZyLOyb2LqmKMMcaEWr1wB2CMMaZ2sgRjjDHGF5ZgjDHG+MISjDHGGF9YgjHGGOMLSzDGGGN8YQnGmEoQkSQRURGpH8S114nI59URlzGRxBKMqfVEZKOI5IlIQonjy7wkkRSeyIyp3SzBmLrie2B88QsR6Q00DF84kSGYGpgxlWUJxtQVrwE/C3j9c2Bq4AUi0kxEpopItohsEpHfi0g971yUiDwpIjtFZANwSSn3viIi20Vkq4j8WUSigglMRP4rIjtEJEdEPhORngHnGorI37x4ckTkcxFp6J07S0QWisheEdkiItd5x+eLyE0BZRzXROfV2m4TkXXAOu/Y014Z+0RkiYicHXB9lIg8ICLfich+73x7EXlORP5W4rO8LyK/CuZzm9rPEoypK74EmopId++Lfyzw7xLXPAM0A04BhuES0vXeuZuBS4H+QDJwVYl7pwAFQBfvmvOBmwjObKAr0BpYCrwecO5J4HRgCNAS+B1QJCIdvPueAVoB/YBlQb4fwOXAGUAP7/Vir4yWwH+A/4pIrHfublzt72KgKXADcMj7zOMDknACMBKYVoE4TG2mqvawR61+ABuBUcDvgceAC4GPgfqAAklAFHAE6BFw3y+A+d7zucAtAefO9+6tD7Tx7m0YcH48MM97fh3weZCxNvfKbYb7A/Aw0LeU6+4H3imjjPnATQGvj3t/r/wR5cSxp/h9gbXA6DKuSwPO857fDswK939ve0TOw9pfTV3yGvAZ0IkSzWNAAhADbAo4tgk42Xt+ErClxLliHYFoYLuIFB+rV+L6Unm1qUeBq3E1kaKAeBoAscB3pdzavozjwTouNhH5Da7GdRIuATX1YijvvaYA1+IS9rXA01WIydQy1kRm6gxV3YTr7L8YeLvE6Z1APi5ZFOsAbPWeb8d90QaeK7YFV4NJUNXm3qOpqvakfD8GRuNqWM1wtSkA8WLKBTqXct+WMo4DHAQaBbxuW8o1R5dR9/pb7gWuAVqoanMgx4uhvPf6NzBaRPoC3YF3y7jO1EGWYExdcyOueehg4EFVLQTeBB4VkTgR6Yjreyjup3kTuFNEEkWkBXBfwL3bgY+Av4lIUxGpJyKdRWRYEPHE4ZLTLlxS+EtAuUXAZODvInKS19l+pog0wPXTjBKRa0SkvojEi0g/79ZlwJUi0khEunifubwYCoBsoL6IPISrwRR7GfiTiHQVp4+IxHsxZuD6b14D3lLVw0F8ZlNHWIIxdYqqfqeqqWWcvgP31/8G4HNcZ/dk79xLwBxgOa4jvmQN6Ge4JrY1uP6LGUC7IEKaimtu2+rd+2WJ8/cAK3Ff4ruBJ4B6qroZVxP7jXd8GdDXu+cfQB6QiWvCep0Tm4MbMPCtF0suxzeh/R2XYD8C9gGvcPwQ7ylAb1ySMeYoUbUNx4wxlSci5+BqeklercsYwGowxpgqEJFo4C7gZUsupiRLMMaYShGR7sBeXFPgU2EOx0QgayIzxhjjC6vBGGOM8UWdnmiZkJCgSUlJ4Q7DGGNqlCVLluxU1VblXVenE0xSUhKpqWWNWDXGGFMaEdlU/lXWRGaMMcYnlmCMMcb4whKMMcYYX9TpPpjS5Ofnk5GRQW5ubrhDqTaxsbEkJiYSHR0d7lCMMbWIJZgSMjIyiIuLIykpiYCl12stVWXXrl1kZGTQqVOncIdjjKlFfG0iE5HJIpIlIqvKOC8iMlFE1ovIChEZEHDu5yKyznv8POD46SKy0rtnonhZQERaisjH3vUfeyveVlhubi7x8fF1IrkAiAjx8fF1qsZmjKkefvfB/Au3e2BZLsJtFdsVmAC8AC5ZAA/jtnQdBDwckDBe8K4tvq+4/PuAFFXtCqQQsJx6RdWV5FKsrn1eY0z18LWJTFU/E5GkE1wyGpiqbr2aL0WkuYi0A4YDH6vqbgAR+Ri4UETmA01VdZF3fCpub/HZXlnDvXKn4LaNvTe0n8iYyKKqHM4vZPfBPPYczGf3oTz2HMxj98E8cg7nY0tBmbIkJ7XknFPLnStZJeHugzmZ4/edyPCOneh4RinHAdp4Gz+hqttFpHVpbygiE3A1IDp06FDaJWG1a9cuRo4cCcCOHTuIioqiVSv3j+Drr78mJiam3DKuv/567rvvPrp16+ZrrCb0cvML2Xso3yWMQ3nH/zyYx+5D+UcTSPHxIwVlL2JslVNTlluGda71Caa0f/5aieNBU9VJwCSA5OTkiPvzLj4+nmXLlgHwhz/8gSZNmnDPPfccd42qoqrUq1d6C+err77qe5ymfPmFRew55NUsfpAofpgw9h7K42BeYZnlNWsYTcvGMbRoFM1JzWPpeVJT97pxDC0beT8bR9OiUQwtG8fQNDaaevUsw5jwCXeCyeD4fc4TgW3e8eEljs/3jieWcj1Apoi082ov7YAsn2IOi/Xr13P55Zdz1lln8dVXX/HBBx/wxz/+kaVLl3L48GHGjh3LQw89BMBZZ53Fs88+S69evUhISOCWW25h9uzZNGrUiPfee4/WrUut3JlKUlW+33mQ1I17WLxxN99s2Uvmvlz25xaUeU9cg/q08JJDQpMYurZpEpAkYo4miRaNomnROIbmDaOpH2XT1kzNEu4EMxO4XUSm4zr0c7wEMQf4S0DH/vnA/aq6W0T2i8hg4CvcNrXPBJT1c+Bx7+d7VQ3uj++vZs22fVUt5jg9TmrKwz/qWal716xZw6uvvsqLL74IwOOPP07Lli0pKCjg3HPP5aqrrqJHjx7H3ZOTk8OwYcN4/PHHufvuu5k8eTL33Vfp8Q8GyCsoYvW2HJZscgkldeMedh3MA6BFo2hO79iCs7oklKhduNpHy0YxNG8UQ0x9Sxam9vM1wYjINFxNJEFEMnAjw6IBVPVFYBZuX/H1wCHgeu/cbhH5E24fcoBHijv8gVtxo9Ma4jr3Z3vHHwfeFJEbgc3A1X5+tnDo3LkzAwcOPPp62rRpvPLKKxQUFLBt2zbWrFnzgwTTsGFDLrroIgBOP/10FixYUK0x1wb7c/NZunkvqRt3s3jjbpZt2Utuvuv36BjfiOHdWjMwqQXJSS3p3KqxjcozxuP3KLLx5ZxX4LYyzk0GJpdyPBXoVcrxXcDIykVausrWNPzSuHHjo8/XrVvH008/zddff03z5s259tprS53LEjgoICoqioKCspttjLM95zCLN+4h1audpO/YR5FCVD2hR7umjB/UgYFJLUnu2ILWTWPDHa4xESvcTWSmkvbt20dcXBxNmzZl+/btzJkzhwsvPNGUI1OaoiLl26z9pHoJZfHGPWzdexiARjFRDOjQgjtHdmVgUkv6tW9O4wb2v4wxwbL/W2qoAQMG0KNHD3r16sUpp5zC0KFDwx1SjZCbX8iKjByv72Q3SzbtYZ/XGd8qrgEDk1pw41mdGJjUku7t4qxj3ZgqkLo8ESs5OVlLbjiWlpZG9+7dwxRR+NTWz73nYB6pm7zmrk17WJmRQ16h6z/p0rqJ6zvp2JKBSS1p37Kh9Z8YEwQRWaKqyeVdZzUYU2uoKlt2H3a1k02uuWt91gEAoqOE3ic34/qhSSQnteT0ji1o2bj8SavGmMqzBGNqhS27D/GL15awZrsbVh4XW5/kji24ov/JDExqSZ/EZsRGR4U5SmPqFkswpsb7ZvMebp6aypGCIh7+UQ/O7BzPqa3jbBa7MWFmCcbUaLNXbudXbyyjVVwDpk8YTJfWceEOyRjjsQRjaiRV5Z+fbeDx2en079Ccl36WTEKTBuEOyxgTwBKMqXHyC4t46L1VTPt6C5f0acffru5r/SvGRCBLMBEmFMv1A0yePJmLL76Ytm3b+hZrOOzLzee215eyYN1Ofjm8M/ec3836WoyJUJZgIkwwy/UHY/LkyQwYMKBWJZgtuw9xw78W8/3Og/x1TB+uGdi+/JuMMWFjCaYGmTJlCs899xx5eXkMGTKEZ599lqKiIq6//nqWLVuGqjJhwgTatGnDsmXLGDt2LA0bNqxQzSdSLduyl5umLOZIQRFTbhjE0C4J4Q7JGFMOSzAnMvs+2LEytGW27Q0XPV7h21atWsU777zDwoULqV+/PhMmTGD69Ol07tyZnTt3snKli3Pv3r00b96cZ555hmeffZZ+/fqFNv4wsJFixtRMlmBqiE8++YTFixeTnOxWZzh8+DDt27fnggsuYO3atdx1111cfPHFnH/++WGONHRUlUmfbeAxGylmTI1kCeZEKlHT8IuqcsMNN/CnP/3pB+dWrFjB7NmzmThxIm+99RaTJk0KQ4ShZSPFjKn5bKnYGmLUqFG8+eab7Ny5E3CjzTZv3kx2djaqytVXX310C2WAuLg49u/fH86QK21fbj43/Gsx077ewi+Hd+aZcf0tuRhTA1kNpobo3bs3Dz/8MKNGjaKoqIjo6GhefPFFoqKiuPHGG1FVRIQnnngCgOuvv56bbrqpxnXy20gxY2oPW67flusHIuNzB44Ue/Ha022kmDERypbrNzWKjRQzpvaxBGPCykaKGVN7+drJLyIXishaEVkvIveVcr6jiKSIyAoRmS8iiQHnnhCRVd5jbMDxBSKyzHtsE5F3vePDRSQn4NxDlY27rjUbhuvz5hcW8cA7K3lsdjqX9G7HtJsHW3IxphbxrQYjIlHAc8B5QAawWERmquqagMueBKaq6hQRGQE8BvxURC4BBgD9gAbApyIyW1X3qerZAe/xFvBeQHkLVPXSqsQdGxvLrl27iI+PrxPb56oqu3btIjY2tlrf19YUM6b287OJbBCwXlU3AIjIdGA0EJhgegC/9p7PA94NOP6pqhYABSKyHLgQeLP4RhGJA0YA14cy6MTERDIyMsjOzg5lsREtNjaWxMTE8i8MkS27D3HjlMVsyLaRYsbUZn4mmJOBLQGvM4AzSlyzHBgDPA1cAcSJSLx3/GER+TvQCDiX4xMT3vUpqrov4NiZXjLaBtyjqqtLBiUiE4AJAB06dPhB0NHR0XTq1CnYz2gqyI0US+VIQaGtKWZMLednH0xp7R0lG/vvAYaJyDfAMGArUKCqHwGzgIXANGARUFDi3vHeuWJLgY6q2hd4hmO1oeMDUJ2kqsmqmly8DL6pHrNXbmfcpEXERtfj7VuHWHIxppbzM8FkAIFtH4m4msVRqrpNVa9U1f7Ag96xHO/no6raT1XPwyWrdcX3ebWcQcD/Asrap6oHvOezgGgRsW+wCKCq/PPT7/jlf5bSvV1T3r1tKF3b2DBkY2o7PxPMYqCriHQSkRhgHDAz8AIRSRCR4hjuByZ7x6O8JIKI9AH6AB8F3Ho18IGq5gaU1Va8XnkRGYT7bLt8+WQmaG6k2Coem53Oxb1spJgxdYlvfTCqWiAitwNzgChgsqquFpFHgFRVnQkMBx4TEQU+A27zbo8GFnj5Yh9wrdfhX2wcUHIlyquAW0WkADgMjNO6Nt44wthIMWPqNlsqpsRSMSY0Mva4NcU2ZB/kL1f0tpFixtQitlSMCRsbKWaMAUswJsQ+XOXWFEto0oBpN59hnfnG1GGWYExIqCovLXBrivVrb2uKGWMswZgQcLtPrmba15u5pHc7/naN7T5pjLEEY0LgkffXMO3rzTZSzBhzHEswpkoKCot4b9lWLu93Er+78LRwh2OMiSC+Ltdvar/UTXvYl1vABT3bhjsUY0yEsQRjqmRuehbRUcLZp9q6bsaY41mCMVWSkpbJ4FPiadLAWluNMcezBGMqbePOg3yXfZCRp7UOdyjGmAhkCcZUWkp6FgAjTmsT5kiMMZHIEoyptJS0TLq2bkKH+EbhDsUYE4EswZhK2Zebz9ff72Zkd6u9GGNKZwnGVMqCb3dSUKSM7G79L8aY0lmCMZWSkpZJ80bRDOjQItyhGGMilCUYU2GFRcq8tVmc2601UbYsjDGmDJZgTIV9s3kPew7lM8KGJxtjTsASjKmwlPQs6tcTzrHZ+8aYE7AEYypsbloWA5Na0qxhdLhDMcZEMEswpkK27D7E2sz9NnrMGFMuSzCmQuZ6s/dt/osxpjy+JhgRuVBE1orIehG5r5TzHUUkRURWiMh8EUkMOPeEiKzyHmMDjv9LRL4XkWXeo593XERkovdeK0RkgJ+fra76JC2TUxIa0ymhcbhDMcZEON8SjIhEAc8BFwE9gPEi0qPEZU8CU1W1D/AI8Jh37yXAAKAfcAbwWxFpGnDfb1W1n/dY5h27COjqPSYAL/jzyequA0cK+GrDbmseM8YExc8azCBgvapuUNU8YDowusQ1PYAU7/m8gPM9gE9VtUBVDwLLgQvLeb/RuGSlqvol0FxE2oXigxjn83U7ySssssUtjTFB8TPBnAxsCXid4R0LtBwY4z2/AogTkXjv+EUi0khEEoBzgfYB9z3qNYP9Q0QaVOD9EJEJIpIqIqnZ2dmV/Wx1UkpaJk1j65OcZLP3jTHl8zPBlDbFW0u8vgcYJiLfAMOArUCBqn4EzAIWAtOARUCBd8/9wGnAQKAlcG8F3g9VnaSqyaqa3KqVzeMIVpE3e39Yt9ZER9nYEGNM+fz8psjg+FpHIrAt8AJV3aaqV6pqf+BB71iO9/NRr4/lPFzyWOcd3+41gx0BXsU1xQX1fqbylmfsZeeBPNtczBgTND8TzGKgq4h0EpEYYBwwM/ACEUkQkeIY7gcme8ejvKYyRKQP0Af4yHvdzvspwOXAKu/+mcDPvNFkg4EcVd3u4+erU+amZ1FPYHg3q/UZY4Lj20bqqlogIrcDc4AoYLKqrhaRR4BUVZ0JDAceExEFPgNu826PBha4HMI+4FpVLW4ie11EWuFqNcuAW7zjs4CLgfXAIeB6vz5bXZSSlkVyx5Y0bxQT7lCMMTWEbwkGQFVn4b74A489FPB8BjCjlPtycSPJSitzRBnHlWMJyoTQtr2HWbN9H/dddFq4QzHG1CDWW2vKVTx7f5TNfzHGVIAlGFOulLRMOrRsROdWTcIdijGmBrEEY07oUF4BX3y3i5HdW+P1iRljTFAswZgTWrh+F3kFRYy02fvGmAqyBGNOKCU9kyYN6jOoU8twh2KMqWEswZgyqSopaVmcc2oCMfXtn4oxpmLsW8OUadXWfWTtP2KLWxpjKsUSjClTSnomInCuzd43xlSCJRhTprnpWfRv35z4Jg3Kv9gYY0qwBGNKlbkvlxUZObY1sjGm0izBmFLN82bv2+6VxpjKsgRjSpWSnsXJzRvSrU1cuEMxxtRQlmDMD+TmF/L5up02e98YUyWWYMwPLNqwi8P5hYywzcWMMVVQboIRkdtFxDZhr0NS0jJpFBPF4FPiwx2KMaYGC6YG0xZYLCJvisiFYm0mtZqqMjcti7O6JBAbHRXucIwxNVi5CUZVfw90BV4BrgPWichfRKSzz7GZMEjfsZ9tObk2eswYU2VB9cF4u0Xu8B4FQAtghoj81cfYTBikpGUCcK71vxhjqqjcLZNF5E7g58BO4GXgt6qaLyL1gHXA7/wN0VSnlPQs+iY2o3VcbLhDMcbUcOUmGCABuFJVNwUeVNUiEbnUn7BMOOw8cIRlW/byq5GnhjsUY0wtEEwT2Sxgd/ELEYkTkTMAVDXtRDd6gwLWish6EbmvlPMdRSRFRFaIyHwRSQw494SIrPIeYwOOv+6VuUpEJotItHd8uIjkiMgy7/FQEJ/NBJiXnoWqzd43xoRGMAnmBeBAwOuD3rETEpEo4DngIqAHMF5EepS47Elgqqr2AR4BHvPuvQQYAPQDzgB+KyJNvXteB04DegMNgZsCylugqv28xyNBfDYTYG56Fm2bxtLzpKblX2yMMeUIJsGI18kPuKYxgmtaGwSsV9UNqpoHTAdGl7imB5DiPZ8XcL4H8KmqFqjqQWA5cKH3/rPUA3wNJGKq7EhBIZ99m80Im71vjAmRYBLMBhG5U0SivcddwIYg7jsZ2BLwOsM7Fmg5MMZ7fgUQJyLx3vGLRKSRiCQA5wLtA2/0msZ+CnwYcPhMEVkuIrNFpGdpQYnIBBFJFZHU7OzsID5G3fD197s5mFfISBs9ZowJkWASzC3AEGArLkmcAUwI4r7S/gzWEq/vAYaJyDfAMO89ClT1I1zfz0JgGrAINzw60PPAZ6q6wHu9FOioqn2BZ4B3SwtKVSeparKqJrdqZRtpFUtJy6JB/XoM6ZwQ7lCMMbVEuU1dqpoFjKtE2RkcX+tIBLaVKHsbcCWAiDQBxqhqjnfuUeBR79x/cEOi8V4/DLQCfhFQ1r6A57NE5HkRSVDVnZWIvU5RVVLSMzmrSwINY2z2vjEmNIKZBxML3Aj0BI5OjlDVG8q5dTHQVUQ64Wom44Aflyg7Adjt9evcD0z2jkcBzVV1l4j0AfoAH3nnbgIuAEZ69xWX1RbIVFUVkUG42tmu8j6fgfVZB9iy+zC3DLPFGYwxoRNME9lruPXILgA+xdVE9pd3k6oWALcDc4A04E1VXS0ij4jIZd5lw4G1IvIt0AavxgJEAwtEZA0wCbjWKw/gRe/aRSWGI18FrBKR5cBEYFzg4ARTtk/SvM3FTrPdK40xoSPlfQeLyDeq2l9EVqhqH69zfY6qjqieEP2TnJysqamp4Q4j7K5+cSGH8gr5351nhzsUY0wNICJLVDW5vOuCqcHkez/3ikgvoBmQVIXYTATZczCPJZv22OgxY0zIBTOfZZK3H8zvgZlAE+D/fI3KVJv532ZRpDCyuzWPGWNC64QJxlvQcp+q7gE+A06plqhMtUlJy6JVXAN6n9ws3KEYY2qZEzaReaO0bq+mWEw1yy8s4tNvsxnRrTX16tnsfWNMaAXTB/OxiNwjIu1FpGXxw/fIjO8Wb9zN/twCRtjilsYYHwTTB1M83+W2gGOKNZfVeClpWcRE1eOsLjZ73xgTesHM5O9UHYGY6jc3PYszO8fTuEEwf2cYY0zFBDOT/2elHVfVqaEPx1SXDdkH+H7nQa4fmhTuUIwxtVQwf7oODHgeC4zELSxpCaYGS/Fm74+w+S/GGJ8E00R2R+BrEWmGWz7G1GAp6Zmc1jaOxBaNwh2KMaaWqkzj+yGga6gDMZXw1T9h9r38cBeE8k0vfvKHEMXSZRSMfwOirD/HGOME0wfzPse+werhdpt808+gTBDyc+GzJ6Ftb+h2cYVuXZu5n9mrtnNNcntOataw6rEczIbUV+CLp+Cce6penjGmVgjmz80nA54XAJtUNcOneEywVkyHg1kw5mU4ZViFbn1h+jd81mAnd1w2CkI1wTJ3L8x/DLqeB+36hqZMY0yNFsxEy83AV6r6qap+AewSkSRfozInVlQEC59xX+SdzqnQrQWFRcxbm8253VoTFcrZ+xc/CY0S4J1bXO3KGFPnBZNg/gsUBbwu9I6ZcFk7C3athyF3glQsSSzdvJecw/mMDPXs/UYtYfRzkLUG5j1a/vXGmFovmARTX1Xzil94z2P8C8mUa+FEaN4Belxe4VtT0jOJjhLO7urD7P2uoyD5Ble72rQw9OUbY2qUYBJMdsAOlIjIaMD2uQ+XzV/Clq/gzNsrNWIrJS2LMzrFExcb7UNwwHl/ghZJrqnsSLkbnxpjarFgEswtwAMisllENgP3Ar/wNyxTpi8mQsMW0P/aCt+6addB1mcd8HdyZYMmcMWLkLMF5jzo3/sYYyJeuQlGVb9T1cG44ck9VXWIqq73PzTzAzvXuf6XgTdDTOMK3148ez/k/S8ldRgMQ++CpVPg2zn+vpcxJmKVm2BE5C8i0lxVD6jqfhFpISJ/ro7gTAkLn4H6DWDQhErdPjc9iy6tm9AxvuLJqcKG3w9tesF7t8PBXf6/nzEm4gTTRHaRqu4tfuHtbhnUzD4RuVBE1orIehG5r5TzHUUkRURWiMh8EUkMOPeEiKzyHmMDjncSka9EZJ2IvCEiMd7xBt7r9d75pGBirDH2Z8LyadB3PDRpVfHbc/P56vtdjKyutcfqN4Ar/gmH98D/fg1a8dUGjDE1WzAJJkpEGhS/EJGGQIMTXF98XRTwHHARrnltvIj0KHHZk8BUVe0DPAI85t17CTAA6AecAfxWRJp69zwB/ENVuwJ7gBu94zcCe1S1C/AP77ra4+t/QmE+DLmj/GtLsWDdTvILlZHd24Q4sBNo2wtGPAhr3oOVM6rvfY0xESGYBPNvIEVEbhSRG4GPgSlB3DcIWK+qG7yhzdOB0SWu6QGkeM/nBZzvAXyqqgWqehBYDlwoIgKMAIq/raYAxWN1RwfENQMY6V1f8x05AItfhu6XQnznShWRkpZFs4bRDOjQPMTBlWPIndD+DJj1G8jZWr3vbYwJq2A6+f8K/Bnojvvi/xDoGETZJwNbAl5neMcCLQfGeM+vAOJEJN47fpGINBKRBOBcoD0QD+xV1YJSyjz6ft75HO/644jIBBFJFZHU7OzsID5GBFg6FXJzYMhdlbq9sEiZtzaL4d1aUT8qmL8pQqhelBtVVlgA791mTWXG1CHBftvswM3mH4PbDyYtiHtKqz2U/Ha5BxgmIt8Aw4CtQIGqfgTMAhYC04BFuHXQTlRmMO+Hqk5S1WRVTW7VquJ9GdWuMB++fB46DIH2A8u/vhTLtuxl98G86m0eC9TyFLjgz7BhnquJGWPqhDITjIicKiIPiUga8CyudiCqeq6qPhtE2Rm4WkexRGBb4AWquk1Vr1TV/sCD3rEc7+ejqtpPVc/DJY91uAmezUWkfillHn0/73wzYHcQcUa21e+6OSVD76x0EXPTM4mqJwzrGsaEevr1bkn/j/4Pdn0XvjiMMdXmRDWYdFxt5UeqepaqPoNbhyxYi4Gu3qivGGAcMDPwAhFJEJHiGO4HJnvHo7ymMkSkD9AH+EhVFddXc5V3z8+B97xDNVkzAAAbhElEQVTnM73XeOfnetfXXKrwxdOQcCp0vaDSxaSkZTEwqQXNGvk0ez8YInDZs2502Tu/cE1mxpha7UQJZgyuaWyeiLwkIiMpvRmqVF4/yO3AHFyT2puqulpEHglYemY4sFZEvgXaAMWrJEYDC0RkDTAJuDag3+Ve4G4RWY/rY3nFO/4KEO8dvxv4wbDoGmfDPMhc6TrK61Wu7yRjzyHSd+xn5Glhah4L1LQdXPp3yFjs9o4xxtRqZS5mparvAO+ISGPcSK1fA21E5AXgHa+f5IRUdRauLyXw2EMBz2dwbERY4DW5uAEFpZW5ATdCrbR7ri4vphrli4nQpC30uabSRcxNd7P3R/g9ez9YvcZA+v9s7xhj6oBgRpEdVNXXVfVSXJ/HMmpD7SDSbV/uajCDb3HNSpWUkpZFp4TGdG7VJITBVVHx3jFv/8L2jjGmFqtQu4uq7lbVf6rqCL8CMp6Fz0BME9c5XkkHjxSw6Ltd/i5uWRnFe8dkp8E8W3XImNqqmidFmKDs3Qyr3obTr4OGlZ8Y+fn6neQVFvm/uGVlHN075lnY+EW4ozHG+MASTCRa9LwbdTX41ioVMzcti7gG9RmY1DJEgYVY8d4x79reMcbURpZgIs2h3W7mfq+roFli+deXoahISUnP4pxurYiu7tn7wTq6d0wGzHkg3NEYY0IsQr956rDUVyD/YKUXtSy2cmsOOw8cYVQkNo8FOrp3zFRY+2G4ozHGhJAlmEiSnwtfTXIz3tv2qlJRKelZ1BMYfmqEJxg4tnfMzDts7xhjahFLMJFkxXQ4mOUmVlZRSlomp3dsQYvGMSEIzGeBe8d88CtbENOYWsISTKQoKnJDk9v1hU7nVKmoHTm5rN62jxGRMHs/WMV7x6TNhJX/DXc0xpgQsAQTKdbOgl3rXX9EFbexSUnPBIjM4cknUrx3zP/usb1jjKkFLMFEioUToXkH6F5yT7aKm5uWRfuWDenaOoJm7wejeO+YogJ475euVmeMqbEswUSCzV/Clq/gzNshqszl4YJyOK+Qz9fvZORpbaiRG3oe3TtmvhtRZ4ypsSzBRIIvJkLDFtD/2ioXtfC7nRwpiNDZ+8EK3Dtm5/pwR2OMqSRLMOGW/a3rfxl4M8Q0rnJxKelZNI6JYlCnCJ29HwzbO8aYWsESTLgtesZ9kQ6aUOWiVJW5aVmc3bUVDepHhSC4MCreO2ZrKnzxj3BHY4ypBEsw4bQ/E5ZPh34/hiZV38549bZ97NiXW7ObxwL1GuMe8x932xcYY2oUSzDh9PU/oTDfde6HwNz0LETg3Ehbnr8qLn4SGreyvWOMqYEswYTLkf2w+GXo/iOI7xySIlPSMunXvjkJTSq/QVnEadQSRj9bs/aOyT9sqxEYgyWY8Fn6GuTmuImVIZC1P5flGTmMrE21l2JdRkHyjZG9d8yRA7BsGkwdDY+2g1fOg00Lwx2VMWFlCSYcCvPhy+ehwxBITA5JkfPTswFq1vIwFXF+BO4dU1gA6z+Bt26GJ7u62PZshDN+4bYgePUimPZjyF4b7kiNCQtfE4yIXCgia0VkvYjcV8r5jiKSIiIrRGS+iCQGnPuriKwWkTQRmShOnIgsC3jsFJGnvOuvE5HsgHM3+fnZqmT1O5CzJWS1F4BP0jI5qVks3dvFhazMiBLT2C2IGe69Y1Rh+wqY8yD8owf8ewysmwN9xsINc+DOZXDRE3DHUhjxf/D9Z/D8YHj/Lti/I3xxGxMGVZs2fgIiEgU8B5wHZACLRWSmqq4JuOxJYKqqThGREcBjwE9FZAgwFOjjXfc5MExV5wP9At5jCfB2QHlvqGpoesz9ouomViZ0g67nh6TI3Hw3e//KASfXzNn7wepwBgz9FXz+d+h2CXS7sPree982WPEmrHgDstZAvWg49QKXWE69wA01DxTTCM65x217/dn/c/1tK950AzqG3gkNaukfAsYE8C3BAIOA9aq6AUBEpgOjgcAE0wP4tfd8HvCu91yBWCAGECAayAwsXES6Aq2BBT7F748N8yBzpZtIWC80FcgvN+ziUF4hI7vX0uaxQMPvh3Ufu71jfvklNI73772O7Ie0991Q8u8/AxQSB8Ilf4OeV7oBCOVpnOBqNIMmwNw/wWd/hdTJMPw+l3yiov2L35gw87OJ7GRgS8DrDO9YoOXAGO/5FUCciMSr6iJcwtnuPeaoalqJe8fjaiyBw3XGeM1tM0SkfWlBicgEEUkVkdTs7OzKfbKq+OJpaNIW+lwTsiLnpmfRMDqKM0/x8cs2UtSPcQti5u71Z++Yo/0qN8GTp8K7t8LeTTDsd67Z66ZPYOBNwSWXQPGd4ep/wU1zodVpMOseeO4MWP2ujTgztZafCaa0tpqS/yfdAwwTkW+AYcBWoEBEugDdgURcUhohIiU3SRkHTAt4/T6QpKp9gE+AKaUFpaqTVDVZVZNbtar65MYK2b7cLeI4+JYfNqlUkqqSkpbF0C4JxEbX8Nn7wWrbC84N4d4xqu6/zYcPBPSrfHR8v8q5D4RmOHni6XDdBzD+DVd7+e/PbcSZqbX8bCLLAAJrEYnAtsALVHUbcCWAiDQBxqhqjohMAL5U1QPeudnAYOAz73VfoL6qLgkoK3Cv3ZeAJ0L+iarqi4kQ08Qt5hgiazP3s3XvYe4Y0SVkZdYIQ+6AtbPd3jEdh0CzxPLvKSlnq0tQwfarhIqI6z/qMgqW/wfm/cWNOOt2MYz6A7Tq5s/7GlPN/KzBLAa6ikgnEYnB1ThmBl4gIgkiUhzD/cBk7/lmXM2mvohE42o3gU1k4zm+9oKItAt4eVmJ68Nv72Y3euz066Bh85AVm5KWBcCI2jj/5UTqRcEVL7i9Y96twN4xR/bDsv/AlMvgHz3hk4dd0r/kb3DPtzDudehxmX/JJVBUfRjws4ARZwtsxJmpVXyrwahqgYjcDswBooDJqrpaRB4BUlV1JjAceExEFFc7uc27fQYwAliJa1b7UFXfDyj+GuDiEm95p4hcBhQAu4HrfPlglbXoefeX6+BbQ1psSlomfRKb0bppbEjLrRFangIXPOr6Yha/DGeUsWBoYYFrmlwxHdI+gILDbk7NsHtdX1iIVlKoNBtxZmop0TrcwZicnKypqan+v9Gh3e6v5e6XwZX/DFmxuw4cIfnRT7hrZFd+NerUkJVbo6jC61fDxs/hlgWQ0PXY8R0rYPkbrhnsYBbENoeeV0DfcW5r5kgd0r3rOzfibPU70CjBRpyZiCMiS1S13FnifvbBmGKpr0D+IffXaAilpGWhCiNr6+z9YIi4tcqeH+z2jrnqVVj9tkss2WnV168SSsUjzs68Az5+yI04+/IFGPkQ9BgduYnRmBKsBuN3DSY/F57qBe36wrVvhazYrH25XDxxAS0bxzDnV+fU7gmWwVj1NswIGDyROAj6jg1+vkqkUnUj2j5+2CXMxIFw3iNuYIMxYWI1mEixfBoczA7psjAFhUXcOf0bDhwp4PWbBltyAeh1pVsHrOBIZPSrhIqIq3l1GeUGJ8x71EacmRrDEoyfiopg0bPQrh8knR2yYp9OWceXG3bz/67qQ7e21gF81Nl3hzsC/9SLggE/dRuwffk8fP6UaxYc8DO3ukFc23BHaMwP2GrKflo7C3atd30vIaplfPptNs/OW8/VpydydXKpixWY2qx4xNldy9zyM9+8DhP7w9xHI2eVaWM8lmD89MXT0LwjdB8dkuK25xzm128s49TWcTwyuldIyjQ1VPEaZ7d/Dade6NY4e7offP2S2w7CmAhgCcYvm7+EjK/dXIaoqrdEFhQWcee0b8jNL+S5nwygYUwdWRbGnFjLU+DqV22NMxORrA/GL19MhIYtoP9PQlLckx99y+KNe3hqbD+6tG4SkjJNLVK8xlnxiLP//hxOToZBN8Npl0KDOvxvZs9GWPFf2LsRWveANr3cw8+VuCPRgSzIXAU7VrmfXc6DPlf7+paWYPyQ/S2s/Z+bKR7TuMrFzU3P5MVPv2P8oA5c3r/kgtTGeEqOOPvs/7m5QdGNofuP3LDtTsPcgIHa7vAeV4tb8QZsXuSONYqHb/597Jq4dtCm57GE07YXxHep+RNaC/Jg57cuiRxNKKvdZONicSdB2z5llxEilmD8sOgZqB/rOmGraOvew9z95nK6t2vKwz/qEYLgTK1XPOKs309gy5duP5vV77qlcuLaQe+roM8494VamxTkua0WVkx3C6EW5rmN/UY+BL2vgebt4UC2248pc/WxL94Nn0KR128VFeOaGtv2Pj75RGptp2StJHO126L76OdpAK1Pg67nHUuirXtW2+exiZahnmi5P9NNrOx/LVz6jyoVlVdQxNhJi1iXeYD37ziLTglVrw2ZOio/F7790P1Fv+4jt0hom15uhYPeV0PTduWXEYlUYesSl0RXvQWHd0PjVtDrKldja9ev/BGcBXmwa13Al7T3RX0gYI/DUms7XUPSvxqUYGslbXq62IrjjO/iS4zBTrS0BBPqBPPJH+Hzf8AdS6o82e/PH6zh5c+/59kf9+fSPieFKEBT5x3c6VY+WDHdfTlLPdd01ndczemv2bPRLQi6fDrs/s61GHS72H2GziNC08xVWm0nO/342kGrbqGv7RzIgh3e+56oVtKm97GEUo21ErAEE5SQJ5gj+92ilp2GwdjXqlTUR6t3MOG1Jfx0cEf+dHkta8owkWPnOlerWfGG21IiujF0v9TVbE4ZHln9NaX1qySd7WLtcRnENvM/htJqOztWlahJBNR2ipNPabWdUmslq9zKH0fLqr5aSUVYgglCyBPMoudhzv1wUwoklvu7L9OW3Ye4ZOICOsY3ZsatZ9KgfgT9T25qp6Ki4/trjuS4rb17X+VqBW17hyeugjxY/7GL69sPj/Wr9B17rF8lEhT3hQRT2ykqiMhaSUVYgglCSBNMYb6b6NaiI1w/q9LFHCko5OoXF/H9zoP8746z6RDfKDTxGROs0vprWvc89qXud3+NKmSkuia8VW9Xrl8lEpTVtyNRXo2kZ0TVSirCFrusbqvfgX0ZbmfEKnhsVjorMnJ48drTLbmY8IiOhZ6Xu8fBXd72B9Pd1gGf/MG//prd37t+lRVvHOtXOe0SN+Kt87k1b/hw/RgvifQExoY7mrCwBBMKqm5iZUI36Hp+pYuZtXI7/1q4keuHJnFhL1u80ESAxvFusuagm2Hn+mP9Ne/8AqIbufk1VemvKatf5ey73QZ9sU1D+WlMNbMEEwrfzXWjTUY/B/Uqt/rOpl0HuXfGCvq2b879F3UPcYDGhEBCFxjxIJz7gFsKacV0WPWOSw4V6a8pq18lcL6KqRWsDyYUfTBTR0NWOvxqRaV2TMzNL2TMCwvJ2HOYD+44i/YtrWnM1BAn7K+5Gpp6w+trS7+KAawPpvpsWwYb5sOoP1Z6O94/fbCG1dv28fLPki25mJrlRP01Hz8MpwxzySPt/drRr2IqxNcEIyIXAk8DUcDLqvp4ifMdgclAK2A3cK2qZnjn/gpcglvx+WPgLlVVEZkPtAMOe8Wcr6pZItIAmAqcDuwCxqrqRj8/HwALn4GYOEi+vvxrS/Hesq28/tVmJpxzCqN6tAlxcMZUo7L6azbMt36VOsq3BCMiUcBzwHlABrBYRGaq6pqAy54EpqrqFBEZATwG/FREhgBDgeLV2D4HhgHzvdc/UdWSbVs3AntUtYuIjAOewO+hG3s2udFjg2+t1CSv77IP8MDbKzm9Ywt+e4FtfWtqkcD+miP7LanUUX7uBzMIWK+qG1Q1D5gOlNx5qweQ4j2fF3BegVggBmgARAOZnNhoYIr3fAYwUvzerP7L51278eBfVvjW3PxCbnt9KTH16/HM+P5ER9nWPKYWErHkUof5+a12MrAl4HWGdyzQcmCM9/wKIE5E4lV1ES7hbPcec1Q1LeC+V0VkmYj8X0ASOfp+qloA5AD+TYM9tBuWTnUdmc0qvoT+H2auJn3Hfv4+th8nNW/oQ4DGGBNefiaY0moPJYes3QMME5FvcE1gW4ECEekCdAcScYljhIic493zE1XtDZztPX5agfdDRCaISKqIpGZnZ5dyS5BSX4H8QzDkjgrf+vbSDKYv3sIvh3fm3G6tKx+DMcZEMD8TTAYQOKA9EdgWeIGqblPVK1W1P/CgdywHV5v5UlUPqOoBYDYw2Du/1fu5H/gPrinuuPcTkfpAM9zAgeOo6iRVTVbV5FatWlXuk+Xnwlf/dDvCtelZoVvXZe7nwXdWMahTS+4+79TKvb8xxtQAfiaYxUBXEekkIjHAOGBm4AUikiAixTHcjxtRBrAZV7OpLyLRuNpNmvc6wbs3GrgUWOXdMxP4uff8KmCu+jXJZ+V/3YqnQ++s0G2H8gr45etLaRQTxTPj+1Pf+l2MMbWYb6PIVLVARG4H5uCGKU9W1dUi8giQqqozgeHAYyKiwGfAbd7tM4ARwEpcM9eHqvq+iDQG5njJJQr4BHjJu+cV4DURWY+ruYzz67PR5xrXcZl0dtC3qCq/f3cV67MPMPWGQbRpGutbeMYYEwlsJn+oNxwrw5uLt/C7t1Zw58iu1jRmjKnRgp3Jb2001SB9xz7+771VDOkcz10ju4Y7HGOMqRaWYHx24Ijrd4mLjeapcf2IqmfrLRlj6gZLMD5SVR58ZyUbdx5k4vh+tI6zfhdjTN1hCcZH077ewnvLtvHrUacypHNCuMMxxphqZQnGJ6u25vCH91dzdtcEbju3S7jDMcaYamcJxgf7c/O5/T9LadEomqfG9qOe9bsYY+og2w8mxFSV+95ayZY9h5l282Dim1RujxhjjKnprAYTYq99uYn/rdzOb84/lUGdWoY7HGOMCRtLMCG0ImMvf/4gjXO7teKWczqHOxxjjAkrSzAhknM4n9v+s5SEJjH8/RrrdzHGGOuDCQFV5XczlrN9by5v/OJMWjSOCXdIxhgTdlaDCYHJX2xkzupM7r3wNE7v2CLc4RhjTESwBFNFSzfv4bFZaYzq3oabzu4U7nCMMSZiWIKpgr2H8rjjP9/Qtlksf7u6L8d2bzbGGGN9MJVUVKT85s3lZO3PZcYtQ2jWKDrcIRljTESxGkwlvbRgAynpWTxwcXf6tm8e7nCMMSbiWIKphNSNu/nrnLVc1Kst1w1JCnc4xhgTkSzBVEJsdBRDOsfzxFV9rN/FGGPKYH0wldDr5Ga8duMZ4Q7DGGMimtVgjDHG+MISjDHGGF/4mmBE5EIRWSsi60XkvlLOdxSRFBFZISLzRSQx4NxfRWS1iKSJyERxGonI/0Qk3Tv3eMD114lItogs8x43+fnZjDHGnJhvCUZEooDngIuAHsB4EelR4rIngamq2gd4BHjMu3cIMBToA/QCBgLDiu9R1dOA/sBQEbkooLw3VLWf93jZp49mjDEmCH7WYAYB61V1g6rmAdOB0SWu6QGkeM/nBZxXIBaIARoA0UCmqh5S1XkAXplLgUSMMcZEHD8TzMnAloDXGd6xQMuBMd7zK4A4EYlX1UW4hLPde8xR1bTAG0WkOfAjjiUogDFec9sMEWlfWlAiMkFEUkUkNTs7u7KfzRhjTDn8TDClTRDREq/vAYaJyDe4JrCtQIGIdAG642onJwMjROScowWL1AemARNVdYN3+H0gyWtu+wSYUlpQqjpJVZNVNblVq1aV/3TGGGNOyM8EkwEE1iISgW2BF6jqNlW9UlX7Aw96x3JwtZkvVfWAqh4AZgODA26dBKxT1acCytqlqke8ly8Bp4f6AxljjAmenxMtFwNdRaQTrmYyDvhx4AUikgDsVtUi4H5gsndqM3CziDyGqwkNA57y7vkz0Ay4qURZ7VR1u/fyMuC4JrXSLFmyZKeIbKrcxyMB2FnJe2sj+30cz34fx9jv4ni14ffRMZiLfEswqlogIrcDc4AoYLKqrhaRR4BUVZ0JDAceExEFPgNu826fAYwAVuKa1T5U1fe9YcwPAunAUm+Zlme9EWN3ishlQAGwG7guiBgr3UYmIqmqmlzZ+2sb+30cz34fx9jv4nh16fchqiW7RUww6tI/kmDY7+N49vs4xn4Xx6tLvw+byW+MMcYXlmAqb1K4A4gw9vs4nv0+jrHfxfHqzO/DmsiMMcb4wmowxhhjfGEJxhhjjC8swVRCeatE1yUi0l5E5nmrXq8WkbvCHVO4iUiUiHwjIh+EO5ZwE5Hm3tJN6d6/kTPDHVO4iMivvf9HVonINBGJDXdMfrMEU0FBrhJdlxQAv1HV7rjVFm6r478PgLsIYqJvHfE0bh7baUBf6ujvRUROBu4EklW1F25u4LjwRuU/SzAVF8wq0XWGqm5X1aXe8/24L5CSi5rWGd5k4EuAOr9dhIg0Bc4BXgG3Arqq7g1vVGFVH2joraXYiBJLZ9VGlmAqLphVouskEUnC7dPzVXgjCaungN8BReEOJAKcAmQDr3pNhi+LSONwBxUOqroVt//VZtwK8Tmq+lF4o/KfJZiKC2aV6DpHRJoAbwG/UtV94Y4nHETkUiBLVZeEO5YIUR8YALzgLWh7EKiTfZYi0gLX0tEJOAloLCLXhjcq/1mCqbhyV4mua0QkGpdcXlfVt8MdTxgNBS4TkY24ptMRIvLv8IYUVhlAhqoW12hn4BJOXTQK+F5Vs1U1H3gbGBLmmHxnCabijq4SLSIxuI66mWGOKWzErTj6CpCmqn8PdzzhpKr3q2qiqibh/l3MVdVa/1dqWVR1B7BFRLp5h0YCa8IYUjhtBgaLSCPv/5mR1IEBD34u118rlbVKdJjDCqehwE+BlSKyzDv2gKrOCmNMJnLcAbzu/TG2Abg+zPGEhap+JSIzcNu8FwDfUAeWjLGlYowxxvjCmsiMMcb4whKMMcYYX1iCMcYY4wtLMMYYY3xhCcYYY4wvLMEY4yMRKRSRZQGPkM1kF5EkEVkVqvKMCTWbB2OMvw6rar9wB2FMOFgNxpgwEJGNIvKEiHztPbp4xzuKSIqIrPB+dvCOtxGRd0RkufcoXmYkSkRe8vYZ+UhEGobtQxlTgiUYY/zVsEQT2diAc/tUdRDwLG4VZrznU1W1D/A6MNE7PhH4VFX74tbzKl49oivwnKr2BPYCY3z+PMYEzWbyG+MjETmgqk1KOb4RGKGqG7zFQneoaryI7ATaqWq+d3y7qiaISDaQqKpHAspIAj5W1a7e63uBaFX9s/+fzJjyWQ3GmPDRMp6XdU1pjgQ8L8T6VU0EsQRjTPiMDfi5yHu+kGNb6f4E+Nx7ngLcCm7bbm+3SGMimv21Y4y/GgasMg1uf/riocoNROQr3B96471jdwKTReS3uN0gi1cfvguYJCI34moqt+J2RjQmYlkfjDFh4PXBJKvqznDHYoxfrInMGGOML6wGY4wxxhdWgzHGGOMLSzDGGGN8YQnGGGOMLyzBGGOM8YUlGGOMMb74/1lRDTTnQ4U5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "# print(history.history)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(SAVE_MODEL_PATH+'model_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 100.00%\n",
      "Testing Accuracy: 96.81%\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "\n",
    "def predict(X):\n",
    "    return np.rint(model.predict(X)) # threshold the predictions to retrieve labels\n",
    "\n",
    "train_acc, test_acc = evaluate_model(predict,\n",
    "                                     x_train, \n",
    "                                     y_train, \n",
    "                                     x_val, \n",
    "                                     y_val)\n",
    "print(\"Training Accuracy: {:.2f}%\".format(train_acc*100))\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence interval: 96.20%-97.42%\n"
     ]
    }
   ],
   "source": [
    "# estimate 95% confidence interval\n",
    "\n",
    "n = x_val.shape[0]\n",
    "lb, ub = error_conf(1-test_acc, n)\n",
    "\n",
    "print(\"confidence interval: {:.2f}%-{:.2f}%\".format((1-ub)*100,(1-lb)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
