{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "gc.disable()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation,TimeDistributed\n",
    "from keras.layers import Bidirectional, LSTM\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate,BatchNormalization,MaxPooling1D, Conv1D\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D, RepeatVector, Permute, merge\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, Model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.layers import concatenate\n",
    "from keras.callbacks import *\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)\n",
    "\n",
    "keras.backend.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#google word2vec\n",
    "# from gensim.models import KeyedVectors as wv\n",
    "# word_vectors = wv.load_word2vec_format('./input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin', binary = True)\n",
    "# EMBEDDING_DIM =300\n",
    "\n",
    "#glove\n",
    "word_vectors = {}\n",
    "f = open('/home/samarth/embeddings/glove.840B.300d/glove.840B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = ''.join(values[:-300])\n",
    "    coefs = np.asarray(values[-300:], dtype='float32')\n",
    "    word_vectors[word] = coefs\n",
    "f.close()\n",
    "EMBEDDING_DIM =300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# texts = []\n",
    "# titles =[]\n",
    "# labels =[]\n",
    "# for label in ['fake','real']:\n",
    "#     for typ in ['gossipcop','politifact']:\n",
    "#         path = './../datasets/FakeNewsNet/code/fakenewsnet_dataset/'+typ+'/'+label+'/*/news content.json'\n",
    "#         files = glob.glob(path)\n",
    "#         for name in tqdm(files):\n",
    "#             with open(name) as json_file:\n",
    "#                 data = json.load(json_file)\n",
    "#                 if label == 'fake': \n",
    "#                     labels.append(1)\n",
    "#                 else:\n",
    "#                     labels.append(0)\n",
    "#                 texts.append(' '.join(word_tokenize(data['text'])))\n",
    "#     #             titles.append(' '.join(word_tokenize(data['title'])))\n",
    "\n",
    "# df = pd.DataFrame()\n",
    "# # df['title'] = title\n",
    "# df['text'] = texts\n",
    "# df['label'] = labels\n",
    "# df.to_pickle('./pickles/text.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./pickles/text.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (17802, 2)\n",
      "Test shape :  (4451, 2)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2,random_state=1)\n",
    "\n",
    "print(\"Train shape : \",df_train.shape)\n",
    "print(\"Test shape : \",df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samarth/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/home/samarth/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 147878 unique tokens.\n",
      "Number of positive and negative reviews in traing and validation set \n",
      "[13534.  4268.]\n",
      "[3360. 1091.]\n"
     ]
    }
   ],
   "source": [
    "# df_train_pos = df_train[df_train['label']==1]\n",
    "# df_train_neg = df_train[df_train['label']==0].sample(len(df_train_pos)*2,random_state=1)\n",
    "# df_train = pd.concat([df_train_pos,df_train_neg])\n",
    "# df_train = df_train.sample(frac=1,random_state=1)\n",
    "# print(\"Train shape : \",df_train.shape)\n",
    "\n",
    "df_train.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)\n",
    "\n",
    "MAX_SEQUENCE_LENGTH=4000\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(lower=False)\n",
    "tokenizer.fit_on_texts(df_train['text'])\n",
    "sequences = tokenizer.texts_to_sequences(df_train['text'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "train_X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\")\n",
    "train_Y = df_train['label']\n",
    "train_Y = to_categorical(np.asarray(train_Y))\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df_test['text'])\n",
    "test_X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\")\n",
    "test_Y = df_test['label']\n",
    "test_Y = to_categorical(np.asarray(test_Y))\n",
    "\n",
    "print('Number of positive and negative reviews in traing and validation set ')\n",
    "print(train_Y.sum(axis=0))\n",
    "print(test_Y.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3658.860914503988\n",
      "2032.0\n",
      "7162.067879495823\n",
      "110958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.6841e+04, 5.7400e+02, 2.0000e+02, 6.5000e+01, 4.7000e+01,\n",
       "        2.7000e+01, 1.1000e+01, 1.4000e+01, 1.3000e+01, 1.0000e+01]),\n",
       " array([     0. ,  11095.8,  22191.6,  33287.4,  44383.2,  55479. ,\n",
       "         66574.8,  77670.6,  88766.4,  99862.2, 110958. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "lengths = []\n",
    "for sent in df_train['text']:\n",
    "#     print(sent)\n",
    "    lengths.append(len(sent))\n",
    "#     if max(sent)>50:\n",
    "#         print(sent)\n",
    "print(np.mean(lengths))\n",
    "print(np.median(lengths))\n",
    "print(np.std(lengths))\n",
    "print(np.max(lengths))\n",
    "plt.hist(lengths,density=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17802, 4000)\n",
      "(17802, 2)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        word_vector = word_vectors[word]\n",
    "#     if word_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = word_vector\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    '''\n",
    "    metric from here \n",
    "    https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
    "    '''\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    # So we only measure F1 on the target y value:\n",
    "    y_true = y_true[:, 0]\n",
    "    y_pred = y_pred[:, 0]\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## garbage collect\n",
    "del df, df_test, df_train, word_vector, word_vectors\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samarth/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=128, kernel_size=3)`\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1108 10:39:23.572723 140670757365568 deprecation_wrapper.py:119] From /home/samarth/anaconda3/envs/tf36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - more complex convolutional neural network\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 4000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 4000, 300)    44363700    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 3998, 128)    115328      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 3997, 128)    153728      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 3996, 128)    192128      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 799, 128)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 799, 128)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 799, 128)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2397, 128)    0           max_pooling1d_1[0][0]            \n",
      "                                                                 max_pooling1d_2[0][0]            \n",
      "                                                                 max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 2393, 128)    82048       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 478, 128)     0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 474, 128)     82048       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 15, 128)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1920)         0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          245888      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            258         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 45,235,126\n",
      "Trainable params: 45,235,126\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samarth/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=128, kernel_size=4)`\n",
      "/home/samarth/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=128, kernel_size=5)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dropout_prob = [0.2,0.2]\n",
    "hidden_dims = 50\n",
    "filter_sizes  = (3,8)\n",
    "num_filters = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "convs = []\n",
    "filter_sizes = [3,4,5]\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "for fsz in filter_sizes:\n",
    "    l_conv = Conv1D(nb_filter=128,filter_length=fsz,activation='relu')(embedded_sequences)\n",
    "    l_pool = MaxPooling1D(5)(l_conv)\n",
    "    convs.append(l_pool)\n",
    "    \n",
    "l_merge = merge.Concatenate(axis=1)(convs)\n",
    "l_cov1= Conv1D(128, 5, activation='relu')(l_merge)\n",
    "l_pool1 = MaxPooling1D(5)(l_cov1)\n",
    "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n",
    "l_pool2 = MaxPooling1D(30)(l_cov2)\n",
    "l_flat = Flatten()(l_pool2)\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "preds = Dense(2, activation='softmax')(l_dense)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "print(\"model fitting - more complex convolutional neural network\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1108 10:39:30.320832 140670757365568 deprecation_wrapper.py:119] From /home/samarth/anaconda3/envs/tf36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15131 samples, validate on 2671 samples\n",
      "Epoch 1/10\n",
      "15131/15131 [==============================] - 85s 6ms/step - loss: 0.4365 - acc: 0.8148 - val_loss: 0.3835 - val_acc: 0.8454\n",
      "Epoch 2/10\n",
      "15131/15131 [==============================] - 86s 6ms/step - loss: 0.3073 - acc: 0.8760 - val_loss: 0.3577 - val_acc: 0.8592\n",
      "Epoch 3/10\n",
      "15131/15131 [==============================] - 86s 6ms/step - loss: 0.1920 - acc: 0.9253 - val_loss: 0.4172 - val_acc: 0.8237\n",
      "Epoch 4/10\n",
      "15131/15131 [==============================] - 87s 6ms/step - loss: 0.1198 - acc: 0.9582 - val_loss: 0.5074 - val_acc: 0.8428\n",
      "Epoch 5/10\n",
      "15131/15131 [==============================] - 87s 6ms/step - loss: 0.0929 - acc: 0.9690 - val_loss: 0.5305 - val_acc: 0.8487\n",
      "Epoch 6/10\n",
      "15131/15131 [==============================] - 87s 6ms/step - loss: 0.0789 - acc: 0.9727 - val_loss: 0.8252 - val_acc: 0.8517\n",
      "Epoch 7/10\n",
      "15131/15131 [==============================] - 87s 6ms/step - loss: 0.0695 - acc: 0.9758 - val_loss: 1.3171 - val_acc: 0.7821\n",
      "Epoch 8/10\n",
      "15131/15131 [==============================] - 87s 6ms/step - loss: 0.0592 - acc: 0.9779 - val_loss: 1.0119 - val_acc: 0.8454\n",
      "Epoch 9/10\n",
      "15131/15131 [==============================] - 87s 6ms/step - loss: 0.0583 - acc: 0.9780 - val_loss: 0.7695 - val_acc: 0.8398\n",
      "Epoch 10/10\n",
      "15131/15131 [==============================] - 87s 6ms/step - loss: 0.0552 - acc: 0.9789 - val_loss: 0.9655 - val_acc: 0.8446\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X, train_Y, epochs=10,batch_size=BATCH_SIZE,validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-eaca56f57fad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4451/4451 [==============================] - 7s 2ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multilabel-indicator but average='binary'. Please choose another average setting.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d62491b9b1fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(test_Y.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# preds[probs[:,0]>=0.5] =1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    718\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    719\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    832\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    835\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0;32m-> 1047\u001b[0;31m                              \"choose another average setting.\" % y_type)\n\u001b[0m\u001b[1;32m   1048\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multilabel-indicator but average='binary'. Please choose another average setting."
     ]
    }
   ],
   "source": [
    "\n",
    "probs= model.predict(test_X,verbose=1,batch_size=50)\n",
    "preds = [0]*len(probs)\n",
    "# print(preds.shape)\n",
    "# print(test_Y.shape)\n",
    "# preds[probs[:,0]>=0.5] =1 \n",
    "print(metrics.f1_score(test_Y, probs>=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics.f1_score(test_Y, (probs>thresh).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
